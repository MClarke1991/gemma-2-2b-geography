{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from sae_lens import SAE, HookedSAETransformer\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = 'results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Disable gradient computation\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load GPT-2 Small model\n",
    "model = HookedSAETransformer.from_pretrained(\"gemma-2-2b\", device=device)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"gpt2-small\")\n",
    "\n",
    "# Load multiple SAEs for different layers\n",
    "saes = []\n",
    "selected_layers = list(range(26))  # Example: select layers 0, 16, and 25\n",
    "for layer in selected_layers:\n",
    "    sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "        release=\"gemma-scope-2b-pt-res-canonical\",\n",
    "        sae_id=f\"layer_{layer}/width_16k/canonical\",\n",
    "        device=device\n",
    "    )\n",
    "    sae.fold_W_dec_norm()\n",
    "    saes.append((layer, sae)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils.logging import disable_progress_bar\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_prompt(city1, city2):\n",
    "    return f\"The distances from {city1}, to the following are: San-Francisco, CA = 347.42 mi, Las Vegas, NV = 224.28 mi, {city2} =\"\n",
    "\n",
    "def find_token_substring_ws_invariant(pattern, string_tokens):\n",
    "    pattern_tokens = model.to_tokens(pattern)[0][1:].cpu().numpy()\n",
    "    string_tokens = string_tokens.cpu().numpy()\n",
    "\n",
    "    def find_token_substring(city1_tokens, out_tokens):\n",
    "        n, m = len(city1_tokens), len(out_tokens)\n",
    "        for i in range(m - n + 1):\n",
    "            if np.array_equal(out_tokens[i:i+n], city1_tokens):\n",
    "                return i, i+n\n",
    "        return None\n",
    "\n",
    "    range_ = find_token_substring(pattern_tokens, string_tokens)\n",
    "    if range_ is None:\n",
    "        pattern_tokens = model.to_tokens(' ' + pattern)[0][1:].cpu().numpy()\n",
    "        range_ = find_token_substring(pattern_tokens, string_tokens)\n",
    "    return range_\n",
    "\n",
    "def extract_digits(prompt, response):\n",
    "    prompt_end = response.find(prompt) + len(prompt)\n",
    "    relevant_text = response[prompt_end:]\n",
    "    match = re.search(r'([\\d,\\.]+)', relevant_text)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def analyze_distance_query(city1, city2, saes):\n",
    "    prompt = generate_prompt(city1, city2)\n",
    "    gen_out = model.generate(prompt, temperature=0)\n",
    "    \n",
    "    output_ids, cache = model.run_with_cache_with_saes(gen_out, saes=[sae for _, sae in saes])\n",
    "    gen_out_tokens = model.to_tokens(gen_out)[0]\n",
    "\n",
    "    city1_range = find_token_substring_ws_invariant(city1, gen_out_tokens)\n",
    "    city2_range = find_token_substring_ws_invariant(city2, gen_out_tokens)\n",
    "    \n",
    "    extracted_digits = extract_digits(prompt, gen_out)\n",
    "    digit_range = find_token_substring_ws_invariant(extracted_digits, gen_out_tokens)\n",
    "\n",
    "    results = {\n",
    "        'city1': city1,\n",
    "        'city2': city2,\n",
    "        'extracted_digits': extracted_digits\n",
    "    }\n",
    "\n",
    "    for layer, sae in saes:\n",
    "        sae_acts = cache[f'blocks.{layer}.hook_resid_post.hook_sae_acts_post'][0]\n",
    "\n",
    "        for name, range_ in [(\"city_1\", city1_range), (\"city_2\", city2_range), (\"distance\", digit_range), (\"end\", (len(gen_out_tokens)-1, len(gen_out_tokens)))]:\n",
    "            if range_ is not None:\n",
    "                for pos in range(range_[0], range_[1]):\n",
    "                    top10 = torch.topk(sae_acts[pos], 10)\n",
    "                    for i, (index, value) in enumerate(zip(top10.indices.tolist(), top10.values.tolist()), 1):\n",
    "                        results[f'layer_{layer}_{name}_max_active_feature_{i}_index'] = index\n",
    "                        results[f'layer_{layer}_{name}_max_active_feature_{i}_activation'] = value\n",
    "            else:\n",
    "                for i in range(1, 11):\n",
    "                    results[f'layer_{layer}_{name}_max_active_feature_{i}_index'] = None\n",
    "                    results[f'layer_{layer}_{name}_max_active_feature_{i}_activation'] = None\n",
    "\n",
    "    return pd.DataFrame([results])\n",
    "\n",
    "# def analyze_distance_query_long(city1, city2, saes):\n",
    "#     prompt = generate_prompt(city1, city2)\n",
    "#     gen_out = model.generate(prompt, temperature=0)\n",
    "    \n",
    "#     output_ids, cache = model.run_with_cache_with_saes(gen_out, saes=[sae for _, sae in saes])\n",
    "#     gen_out_tokens = model.to_tokens(gen_out)[0]\n",
    "\n",
    "#     city1_range = find_token_substring_ws_invariant(city1, gen_out_tokens)\n",
    "#     city2_range = find_token_substring_ws_invariant(city2, gen_out_tokens)\n",
    "    \n",
    "#     extracted_digits = extract_digits(prompt, gen_out)\n",
    "#     digit_range = find_token_substring_ws_invariant(extracted_digits, gen_out_tokens)\n",
    "\n",
    "#     results = []\n",
    "\n",
    "#     for layer, sae in saes:\n",
    "#         sae_acts = cache[f'blocks.{layer}.hook_resid_post.hook_sae_acts_post'][0]\n",
    "\n",
    "#         for feature_type, range_ in [(\"city_1\", city1_range), (\"city_2\", city2_range), (\"distance\", digit_range), (\"end\", (len(gen_out_tokens)-1, len(gen_out_tokens)))]:\n",
    "#             if range_ is not None:\n",
    "#                 for pos in range(range_[0], range_[1]):\n",
    "#                     top10 = torch.topk(sae_acts[pos], 10)\n",
    "#                     for index, value in zip(top10.indices.tolist(), top10.values.tolist()):\n",
    "#                         results.append({\n",
    "#                             'city1': city1,\n",
    "#                             'city2': city2,\n",
    "#                             'Extracted Distance': extracted_digits,\n",
    "#                             'Feature Type': feature_type,\n",
    "#                             'Feature Index': index,\n",
    "#                             'Feature Activation': value,\n",
    "#                             'SAE_Layer': layer\n",
    "#                         })\n",
    "#             else:\n",
    "#                 # If range is None, add a single row with None values\n",
    "#                 results.append({\n",
    "#                     'city1': city1,\n",
    "#                     'city2': city2,\n",
    "#                     'Extracted Distance': extracted_digits,\n",
    "#                     'Feature Type': feature_type,\n",
    "#                     'Feature Index': None,\n",
    "#                     'Feature Activation': None,\n",
    "#                     'SAE_Layer': layer\n",
    "#                 })\n",
    "\n",
    "#     return pd.DataFrame(results)\n",
    "\n",
    "def analyze_multiple_queries(queries, saes):\n",
    "    results = []\n",
    "    for city1, city2 in tqdm(queries):\n",
    "        result_df = analyze_distance_query(city1, city2, saes)\n",
    "        results.append(result_df)\n",
    "    return pd.concat(results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_city_distances = pd.read_csv(os.path.join(results_dir, 'city_distances_export.csv'))\n",
    "cities = true_city_distances['City 1'].unique().tolist() + true_city_distances['City 2'].unique().tolist()\n",
    "cities = list(set(cities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_city = 'Los Angeles, CA'\n",
    "if not root_city in cities:\n",
    "    raise ValueError(f\"Root city {root_city} not found in the city list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queries_from_root_city(root_city, cities):\n",
    "    return [(root_city, city) for city in cities if city != root_city]\n",
    "\n",
    "\n",
    "queries = queries_from_root_city(root_city, cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "# queries = [\n",
    "#     (\"Los Angeles, CA\", \"New York, NY\"),\n",
    "#     (\"Chicago, IL\", \"Miami, FL\"),\n",
    "#     (\"Seattle, WA\", \"Houston, TX\")\n",
    "# ]\n",
    "\n",
    "results_df = analyze_multiple_queries(queries, saes)\n",
    "\n",
    "# Display the first few rows and columns of the DataFrame\n",
    "print(results_df.head().to_string())\n",
    "\n",
    "root_city_save = root_city.replace(' ', '_').replace(',', '-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(os.path.join(results_dir, f'distance_query_results_root_{root_city_save}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_results(results_df):\n",
    "    all_pivots_complete = []\n",
    "    \n",
    "    for feature_type in ['city_2', 'distance', 'end']:\n",
    "        for layer in range(26):  # 0 to 26\n",
    "            for rank in range(1, 11):  # 1 to 10\n",
    "                index_col = f'layer_{layer}_{feature_type}_max_active_feature_{rank}_index'\n",
    "                activation_col = f'layer_{layer}_{feature_type}_max_active_feature_{rank}_activation'\n",
    "                \n",
    "                if index_col in results_df.columns and activation_col in results_df.columns:\n",
    "                    pivot = results_df[['city1', 'city2', 'extracted_digits', index_col, activation_col]].copy()\n",
    "                    pivot.columns = ['city1', 'city2', 'extracted_digits', 'index', 'activation']\n",
    "                    pivot['sae_layer'] = layer\n",
    "                    pivot['feature_type'] = feature_type\n",
    "                    all_pivots_complete.append(pivot)\n",
    "    \n",
    "    return pd.concat(all_pivots_complete, ignore_index=True)\n",
    "\n",
    "# Apply the transformation\n",
    "transformed_results = transform_results(results_df)\n",
    "\n",
    "# Display the first few rows of the transformed DataFrame\n",
    "print(transformed_results.head())\n",
    "\n",
    "# Save the transformed results to a new CSV file\n",
    "transformed_results.to_csv(os.path.join(results_dir, f'transformed_distance_query_results_root_{root_city_save}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many rows in transformed results are city2 == New York, NY and layer 0\n",
    "print(transformed_results[(transformed_results['city2'] == 'New York, NY') & (transformed_results['sae_layer'] == 0)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
